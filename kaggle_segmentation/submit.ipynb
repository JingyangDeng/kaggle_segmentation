{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import init_segmentor, inference_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import binary_closing, binary_opening, measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangzr/mmsegmentation_kaggle/mmseg/models/losses/cross_entropy_loss.py:238: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ../cache/upernet_originsize_convnext_base_fp16_256x256_160k_kaggle_25d_multilabel/best_mDice_iter_64000.pth\n"
     ]
    }
   ],
   "source": [
    "config_file = '../cache/upernet_originsize_convnext_base_fp16_256x256_160k_kaggle_25d_multilabel/upernet_originsize_convnext_base_fp16_256x256_160k_kaggle_25d_multilabel.py'\n",
    "checkpoint_file = '../cache/upernet_originsize_convnext_base_fp16_256x256_160k_kaggle_25d_multilabel/best_mDice_iter_64000.pth'\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_segmentor(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(row):\n",
    "    data = row['id'].split('_')\n",
    "    case = int(data[0].replace('case',''))\n",
    "    day = int(data[1].replace('day',''))\n",
    "    slice_ = int(data[-1])\n",
    "    row['case'] = case\n",
    "    row['day'] = day\n",
    "    row['slice'] = slice_\n",
    "    return row\n",
    "\n",
    "def path2info(row):\n",
    "    path = row['image_path']\n",
    "    data = path.split('/')\n",
    "    slice_ = int(data[-1].split('_')[1])\n",
    "    case = int(data[-3].split('_')[0].replace('case',''))\n",
    "    day = int(data[-3].split('_')[1].replace('day',''))\n",
    "    width = int(data[-1].split('_')[2])\n",
    "    height = int(data[-1].split('_')[3])\n",
    "    row['height'] = height\n",
    "    row['width'] = width\n",
    "    row['case'] = case\n",
    "    row['day'] = day\n",
    "    row['slice'] = slice_\n",
    "#     row['id'] = f'case{case}_day{day}_slice_{slice_}'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = [320, 384]\n",
    "def load_img(path, size=IMG_SIZE):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    shape0 = np.array(img.shape[:2])\n",
    "    resize = np.array(size)\n",
    "    if np.any(shape0!=resize):\n",
    "        diff = resize - shape0\n",
    "        pad0 = diff[0]\n",
    "        pad1 = diff[1]\n",
    "        pady = [pad0//2, pad0//2 + pad0%2]\n",
    "        padx = [pad1//2, pad1//2 + pad1%2]\n",
    "        img = np.pad(img, [pady, padx])\n",
    "        # img = img.reshape((*resize))\n",
    "        img = img.reshape((resize))\n",
    "    return img, shape0\n",
    "\n",
    "def load_imgs(img_paths, size=IMG_SIZE):\n",
    "    imgs = np.zeros((*size, len(img_paths)), dtype=np.float32)\n",
    "    for i, img_path in enumerate(img_paths):\n",
    "        if i==0:\n",
    "            img, shape0 = load_img(img_path, size=size)\n",
    "        else:\n",
    "            img, _ = load_img(img_path, size=size)\n",
    "        img = img.astype('float32') # original is uint16\n",
    "        mx = np.max(img)\n",
    "        if mx:\n",
    "            img/=mx # scale image to [0, 1]\n",
    "        imgs[..., i]+=img\n",
    "    return imgs, shape0\n",
    "\n",
    "def load_msk(path, size=IMG_SIZE):\n",
    "    msk = np.load(path)\n",
    "    shape0 = np.array(msk.shape[:2])\n",
    "    resize = np.array(size)\n",
    "    if np.any(shape0!=resize):\n",
    "        diff = resize - shape0\n",
    "        pad0 = diff[0]\n",
    "        pad1 = diff[1]\n",
    "        pady = [pad0//2, pad0//2 + pad0%2]\n",
    "        padx = [pad1//2, pad1//2 + pad1%2]\n",
    "        msk = np.pad(msk, [pady, padx, [0,0]])\n",
    "        msk = msk.reshape((*resize, 3))\n",
    "    msk = msk.astype('float32')\n",
    "    msk/=255.0\n",
    "    return msk\n",
    "\n",
    "def show_img(img, mask=None):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img)\n",
    "    plt.imshow(img, cmap='bone')\n",
    "    \n",
    "    if mask is not None:\n",
    "        # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
    "        labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n",
    "        plt.legend(handles,labels)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "\n",
    "# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make test submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'progress_apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/zhangzr/mmsegmentation_kaggle/kaggle_segmentation/submit.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B162.105.94.12/home/zhangzr/mmsegmentation_kaggle/kaggle_segmentation/submit.ipynb#ch0000004vscode-remote?line=7'>8</a>\u001b[0m     debug \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B162.105.94.12/home/zhangzr/mmsegmentation_kaggle/kaggle_segmentation/submit.ipynb#ch0000004vscode-remote?line=8'>9</a>\u001b[0m     sub_df \u001b[39m=\u001b[39m sub_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mpredicted\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mdrop_duplicates()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B162.105.94.12/home/zhangzr/mmsegmentation_kaggle/kaggle_segmentation/submit.ipynb#ch0000004vscode-remote?line=9'>10</a>\u001b[0m sub_df \u001b[39m=\u001b[39m sub_df\u001b[39m.\u001b[39;49mprogress_apply(get_metadata,axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/pandas/core/generic.py?line=5567'>5568</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/pandas/core/generic.py?line=5568'>5569</a>\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/pandas/core/generic.py?line=5569'>5570</a>\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/pandas/core/generic.py?line=5570'>5571</a>\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/pandas/core/generic.py?line=5571'>5572</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/pandas/core/generic.py?line=5572'>5573</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/pandas/core/generic.py?line=5573'>5574</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/pandas/core/generic.py?line=5574'>5575</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'progress_apply'"
     ]
    }
   ],
   "source": [
    "sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n",
    "if not len(sub_df):\n",
    "    debug = True\n",
    "    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\n",
    "    sub_df = sub_df[~sub_df.segmentation.isna()][:1000*3]\n",
    "    sub_df = sub_df.drop(columns=['class','segmentation']).drop_duplicates()\n",
    "else:\n",
    "    debug = False\n",
    "    sub_df = sub_df.drop(columns=['class','predicted']).drop_duplicates()\n",
    "sub_df = sub_df.progress_apply(get_metadata,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/uw-madison-gi-tract-image-segmentation/train/case123/case123_day20/scans/slice_0001_266_266_1.50_1.50.png\n",
      "['../input/uw-madison-gi-tract-image-segmentation/train/case123/case123_day20/scans/slice_0001_266_266_1.50_1.50.png', '../input/uw-madison-gi-tract-image-segmentation/train/case123/case123_day20/scans/slice_0002_266_266_1.50_1.50.png', '../input/uw-madison-gi-tract-image-segmentation/train/case123/case123_day20/scans/slice_0003_266_266_1.50_1.50.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/uw-madison-gi-tract-image-segmentation/train/case123/case123_day20/scans/slice_0002_266_266_1.50_1.50.png\n",
      "['../input/uw-madison-gi-tract-image-segmentation/train/case123/case123_day20/scans/slice_0001_266_266_1.50_1.50.png', '../input/uw-madison-gi-tract-image-segmentation/train/case123/case123_day20/scans/slice_0002_266_266_1.50_1.50.png', '../input/uw-madison-gi-tract-image-segmentation/train/case123/case123_day20/scans/slice_0003_266_266_1.50_1.50.png', '../input/uw-madison-gi-tract-image-segmentation/train/case123/case123_day20/scans/slice_0004_266_266_1.50_1.50.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /io/opencv/modules/core/src/arithm.cpp:647: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/home/zhangzr/mmsegmentation_kaggle/kaggle_segmentation/submit.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B162.105.94.12/home/zhangzr/mmsegmentation_kaggle/kaggle_segmentation/submit.ipynb#ch0000006vscode-remote?line=8'>9</a>\u001b[0m imgs \u001b[39m=\u001b[39m load_imgs(file_names)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B162.105.94.12/home/zhangzr/mmsegmentation_kaggle/kaggle_segmentation/submit.ipynb#ch0000006vscode-remote?line=9'>10</a>\u001b[0m \u001b[39m# new_img = new_img.astype(np.float32) / new_img.max()\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B162.105.94.12/home/zhangzr/mmsegmentation_kaggle/kaggle_segmentation/submit.ipynb#ch0000006vscode-remote?line=10'>11</a>\u001b[0m res \u001b[39m=\u001b[39m inference_segmentor(model, imgs)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B162.105.94.12/home/zhangzr/mmsegmentation_kaggle/kaggle_segmentation/submit.ipynb#ch0000006vscode-remote?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B162.105.94.12/home/zhangzr/mmsegmentation_kaggle/kaggle_segmentation/submit.ipynb#ch0000006vscode-remote?line=12'>13</a>\u001b[0m     rle \u001b[39m=\u001b[39m rle_encode(res[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,j])\n",
      "File \u001b[0;32m~/mmsegmentation_kaggle/mmseg/apis/inference.py:88\u001b[0m, in \u001b[0;36minference_segmentor\u001b[0;34m(model, img)\u001b[0m\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/apis/inference.py?line=85'>86</a>\u001b[0m \u001b[39m# prepare data\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/apis/inference.py?line=86'>87</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(img\u001b[39m=\u001b[39mimg)\n\u001b[0;32m---> <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/apis/inference.py?line=87'>88</a>\u001b[0m data \u001b[39m=\u001b[39m test_pipeline(data)\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/apis/inference.py?line=88'>89</a>\u001b[0m data \u001b[39m=\u001b[39m collate([data], samples_per_gpu\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/apis/inference.py?line=89'>90</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnext\u001b[39m(model\u001b[39m.\u001b[39mparameters())\u001b[39m.\u001b[39mis_cuda:\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/apis/inference.py?line=90'>91</a>\u001b[0m     \u001b[39m# scatter to specified GPU\u001b[39;00m\n",
      "File \u001b[0;32m~/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py:41\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=30'>31</a>\u001b[0m \u001b[39m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=31'>32</a>\u001b[0m \n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=32'>33</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=36'>37</a>\u001b[0m \u001b[39m   dict: Transformed data.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=37'>38</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=40'>41</a>\u001b[0m     data \u001b[39m=\u001b[39m t(data)\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=41'>42</a>\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=42'>43</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mmsegmentation_kaggle/mmseg/datasets/pipelines/test_time_aug.py:120\u001b[0m, in \u001b[0;36mMultiScaleFlipAug.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/test_time_aug.py?line=117'>118</a>\u001b[0m             _results[\u001b[39m'\u001b[39m\u001b[39mflip\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m flip\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/test_time_aug.py?line=118'>119</a>\u001b[0m             _results[\u001b[39m'\u001b[39m\u001b[39mflip_direction\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m direction\n\u001b[0;32m--> <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/test_time_aug.py?line=119'>120</a>\u001b[0m             data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransforms(_results)\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/test_time_aug.py?line=120'>121</a>\u001b[0m             aug_data\u001b[39m.\u001b[39mappend(data)\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/test_time_aug.py?line=121'>122</a>\u001b[0m \u001b[39m# list of dict to dict of list\u001b[39;00m\n",
      "File \u001b[0;32m~/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py:41\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=30'>31</a>\u001b[0m \u001b[39m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=31'>32</a>\u001b[0m \n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=32'>33</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=36'>37</a>\u001b[0m \u001b[39m   dict: Transformed data.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=37'>38</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=40'>41</a>\u001b[0m     data \u001b[39m=\u001b[39m t(data)\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=41'>42</a>\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/compose.py?line=42'>43</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mmsegmentation_kaggle/mmseg/datasets/pipelines/transforms.py:479\u001b[0m, in \u001b[0;36mNormalize.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/transforms.py?line=467'>468</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, results):\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/transforms.py?line=468'>469</a>\u001b[0m     \u001b[39m\"\"\"Call function to normalize images.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/transforms.py?line=469'>470</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/transforms.py?line=470'>471</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/transforms.py?line=475'>476</a>\u001b[0m \u001b[39m            result dict.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/transforms.py?line=476'>477</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/transforms.py?line=478'>479</a>\u001b[0m     results[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m mmcv\u001b[39m.\u001b[39;49mimnormalize(results[\u001b[39m'\u001b[39;49m\u001b[39mimg\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstd,\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/transforms.py?line=479'>480</a>\u001b[0m                                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_rgb)\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/transforms.py?line=480'>481</a>\u001b[0m     results[\u001b[39m'\u001b[39m\u001b[39mimg_norm_cfg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/transforms.py?line=481'>482</a>\u001b[0m         mean\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean, std\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstd, to_rgb\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_rgb)\n\u001b[1;32m    <a href='file:///home/zhangzr/mmsegmentation_kaggle/mmseg/datasets/pipelines/transforms.py?line=482'>483</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py:22\u001b[0m, in \u001b[0;36mimnormalize\u001b[0;34m(img, mean, std, to_rgb)\u001b[0m\n\u001b[1;32m     <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py?line=9'>10</a>\u001b[0m \u001b[39m\"\"\"Normalize an image with mean and std.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py?line=10'>11</a>\u001b[0m \n\u001b[1;32m     <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py?line=11'>12</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py?line=18'>19</a>\u001b[0m \u001b[39m    ndarray: The normalized image.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py?line=19'>20</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py?line=20'>21</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mcopy()\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py?line=21'>22</a>\u001b[0m \u001b[39mreturn\u001b[39;00m imnormalize_(img, mean, std, to_rgb)\n",
      "File \u001b[0;32m~/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py:43\u001b[0m, in \u001b[0;36mimnormalize_\u001b[0;34m(img, mean, std, to_rgb)\u001b[0m\n\u001b[1;32m     <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py?line=40'>41</a>\u001b[0m \u001b[39mif\u001b[39;00m to_rgb:\n\u001b[1;32m     <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py?line=41'>42</a>\u001b[0m     cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB, img)  \u001b[39m# inplace\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py?line=42'>43</a>\u001b[0m cv2\u001b[39m.\u001b[39;49msubtract(img, mean, img)  \u001b[39m# inplace\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py?line=43'>44</a>\u001b[0m cv2\u001b[39m.\u001b[39mmultiply(img, stdinv, img)  \u001b[39m# inplace\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/zhangzr/anaconda3/envs/mmseg-kaggle/lib/python3.10/site-packages/mmcv/image/photometric.py?line=44'>45</a>\u001b[0m \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /io/opencv/modules/core/src/arithm.cpp:647: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n"
     ]
    }
   ],
   "source": [
    "subs = []\n",
    "for day, group in tqdm(sub.groupby(\"days\")):\n",
    "    for file_name in group.file_name.unique():\n",
    "        print(file_name)\n",
    "        s = int(os.path.basename(file_name).split(\"_\")[1])\n",
    "        file_names = [file_name.replace(f\"slice_{s:04d}\", f\"slice_{s + i:04d}\") for i in range(-2, 3)]\n",
    "        file_names = [_ for _ in file_names if os.path.exists(_)]\n",
    "        print(file_names)\n",
    "        imgs = load_imgs(file_names)\n",
    "        # new_img = new_img.astype(np.float32) / new_img.max()\n",
    "        res = inference_segmentor(model, imgs)[0]\n",
    "        for j in range(3):\n",
    "            rle = rle_encode(res[...,j])\n",
    "            index = fname2index[file_name + classes[j]]\n",
    "            sub.loc[index, \"predicted\"] = rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>stomach</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>case123_day20_slice_0099</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>case123_day20_slice_0099</td>\n",
       "      <td>stomach</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>case123_day20_slice_0100</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>case123_day20_slice_0100</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>case123_day20_slice_0100</td>\n",
       "      <td>stomach</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id        class predicted\n",
       "0    case123_day20_slice_0001  large_bowel          \n",
       "1    case123_day20_slice_0001  small_bowel          \n",
       "2    case123_day20_slice_0001      stomach          \n",
       "3    case123_day20_slice_0002  large_bowel          \n",
       "4    case123_day20_slice_0002  small_bowel          \n",
       "..                        ...          ...       ...\n",
       "295  case123_day20_slice_0099  small_bowel          \n",
       "296  case123_day20_slice_0099      stomach          \n",
       "297  case123_day20_slice_0100  large_bowel          \n",
       "298  case123_day20_slice_0100  small_bowel          \n",
       "299  case123_day20_slice_0100      stomach          \n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = sub[[\"id\", \"class\", \"predicted\"]]\n",
    "sub.to_csv(\"submission.csv\", index = False)\n",
    "sub"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9656c464f062ccfd8ba96c4c3c9350bea1c8e56fc9e2ebfcd9f84a4e99b89eff"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mmseg-kaggle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
